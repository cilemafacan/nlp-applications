{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Œ Metin Ã–n Ä°ÅŸleme: Neden Ã–nemlidir?\n",
    "\n",
    "DoÄŸal Dil Ä°ÅŸleme (NLP) projelerinde ham metin verisi, Ã§oÄŸu zaman doÄŸrudan analiz veya modelleme iÃ§in kullanÄ±lamaz. Metinler; dÃ¼zensiz karakterler, noktalama iÅŸaretleri, gereksiz kelimeler ve biÃ§imsel farklÄ±lÄ±klar iÃ§erebilir. Bu nedenle, metinlerin doÄŸru ve etkili bir ÅŸekilde iÅŸlenebilmesi iÃ§in Ã¶n iÅŸleme adÄ±mlarÄ± uygulanmalÄ±dÄ±r.\n",
    "\n",
    "Metin Ã¶n iÅŸleme, veriyi daha temiz, tutarlÄ± ve iÅŸlenebilir hale getirmek iÃ§in yapÄ±lan bir dizi dÃ¶nÃ¼ÅŸÃ¼m sÃ¼recini kapsar. Bu sÃ¼reÃ§, kullanÄ±lan modele ve uygulama alanÄ±na baÄŸlÄ± olarak deÄŸiÅŸebilir ancak genel olarak ÅŸu nedenlerle kritik bir Ã¶neme sahiptir:\n",
    "\n",
    "âœ… **GÃ¼rÃ¼ltÃ¼yÃ¼ Azaltma**: Gereksiz karakterler, semboller ve durak (stop) kelimelerinin kaldÄ±rÄ±lmasÄ±, veriyi daha anlamlÄ± hale getirir.  \n",
    "âœ… **Veri TutarlÄ±lÄ±ÄŸÄ±nÄ± ArtÄ±rma**: FarklÄ± biÃ§imlerde yazÄ±lmÄ±ÅŸ kelimeleri normalize etmek, metnin daha tutarlÄ± olmasÄ±nÄ± saÄŸlar.  \n",
    "âœ… **Hesaplama Maliyetini Azaltma**: Gereksiz veriyi eleyerek modelin daha verimli Ã§alÄ±ÅŸmasÄ±na yardÄ±mcÄ± olur.  \n",
    "âœ… **GenelleÅŸtirme YeteneÄŸini ArtÄ±rma**: Kelime kÃ¶klerine indirgeme (stemming/lemmatization) gibi iÅŸlemler, modelin farklÄ± baÄŸlamlarda da iyi performans gÃ¶stermesini saÄŸlar.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Metin Ã–n Ä°ÅŸleme AÅŸamalarÄ±  \n",
    "\n",
    "Metin Ã¶n iÅŸleme sÃ¼reci, Ã§eÅŸitli dÃ¶nÃ¼ÅŸÃ¼mleri iÃ§eren birden fazla adÄ±mdan oluÅŸur:\n",
    "\n",
    "1ï¸âƒ£ **BÃ¼yÃ¼k/KÃ¼Ã§Ã¼k Harf DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Lowercasing)**: Metindeki tÃ¼m harflerin kÃ¼Ã§Ã¼k harfe Ã§evrilmesi.  \n",
    "2ï¸âƒ£ **Noktalama Ä°ÅŸaretlerinin KaldÄ±rÄ±lmasÄ± (Removing Punctuation)**: Noktalama iÅŸaretlerinin silinmesi veya gerektiÄŸinde deÄŸiÅŸtirilmesi.  \n",
    "3ï¸âƒ£ **SayÄ±larÄ±n KaldÄ±rÄ±lmasÄ± (Removing Numbers)**: SayÄ±larÄ±n metinden Ã§Ä±karÄ±lmasÄ± (bazÄ± durumlarda korunabilir).  \n",
    "4ï¸âƒ£ **Durak Kelimelerin KaldÄ±rÄ±lmasÄ± (Removing Stopwords)**: \"ve\", \"bu\", \"bir\" gibi bilgi taÅŸÄ±mayan yaygÄ±n kelimelerin Ã§Ä±karÄ±lmasÄ±.  \n",
    "5ï¸âƒ£ **Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ± (Removing Special Characters & Emojis)**: Metindeki Ã¶zel sembollerin ve emojilerin temizlenmesi.  \n",
    "6ï¸âƒ£ **Metin Normalizasyonu (Text Normalization)**: Kelimelerin standart bir forma dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi (Ã¶rneÄŸin, \"olmÄ±yacak\" â†’ \"olmayacak\", \"tlfn\" â†’ \"telefon\").  \n",
    "7ï¸âƒ£ **KÃ¶k veya GÃ¶vdeye Ä°ndirgeme (Stemming & Lemmatization)**: Kelimeleri kÃ¶k haline getirme (stemming) veya kÃ¶kÃ¼ne en yakÄ±n hÃ¢le getirme (lemmatization).  \n",
    "8ï¸âƒ£ **Kelime Tokenizasyonu (Tokenization)**: Metni kelime veya cÃ¼mlelere ayÄ±rma.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/cilem/.cache/kagglehub/datasets/mustfkeskin/turkish-movie-sentiment-analysis-dataset/versions/1\n",
      "Dataset name: turkish_movie_sentiment_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "path = kagglehub.dataset_download(\"mustfkeskin/turkish-movie-sentiment-analysis-dataset\")\n",
    "dataset_name = os.listdir(path)[0]\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"Dataset name:\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu mÃ¼thiÅŸ..\n",
      "film ise baÅŸyapÄ±t..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                      Jean Reno denince zate...</td>\n",
       "      <td>Sevginin GÃ¼cÃ¼</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                      EkÅŸÄ±n falan izlemek is...</td>\n",
       "      <td>Sevginin GÃ¼cÃ¼</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                      Bu yapÄ±m hakkÄ±nda Ã¶yle...</td>\n",
       "      <td>Sevginin GÃ¼cÃ¼</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                      finali yeter... (sting...</td>\n",
       "      <td>Sevginin GÃ¼cÃ¼</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n                      Jean Reno..\\r\\nbu adam...</td>\n",
       "      <td>Sevginin GÃ¼cÃ¼</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name point\n",
       "0  \\n                      Jean Reno denince zate...  Sevginin GÃ¼cÃ¼   5,0\n",
       "1  \\n                      EkÅŸÄ±n falan izlemek is...  Sevginin GÃ¼cÃ¼   5,0\n",
       "2  \\n                      Bu yapÄ±m hakkÄ±nda Ã¶yle...  Sevginin GÃ¼cÃ¼   5,0\n",
       "3  \\n                      finali yeter... (sting...  Sevginin GÃ¼cÃ¼   5,0\n",
       "4  \\n                      Jean Reno..\\r\\nbu adam...  Sevginin GÃ¼cÃ¼   5,0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path, dataset_name))\n",
    "print(df[\"comment\"][4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 1. AÅŸama: Lowercasing (KÃ¼Ã§Ã¼k Harfe Ã‡evirme)\n",
    "\n",
    "**Neden Ã–nemlidir?**  \n",
    "Metinlerde bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarlÄ±lÄ±ÄŸÄ± nedeniyle aynÄ± kelimeler farklÄ± ÅŸekilde yorumlanabilir.  \n",
    "Ã–rneÄŸin, \"Film\" ve \"film\" kelimeleri aslÄ±nda aynÄ±dÄ±r, ancak bÃ¼yÃ¼k harf farkÄ± nedeniyle farklÄ± olarak algÄ±lanabilir.  \n",
    "Bunu Ã¶nlemek iÃ§in tÃ¼m metni kÃ¼Ã§Ã¼k harfe Ã§evirmeliyiz.\n",
    "\n",
    "### ğŸ”¹ Ã–rnek:\n",
    "- **Girdi:** `\"Bu Film HARÄ°KAYDI!\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"bu film harikaydÄ±!\"`\n",
    "\n",
    "AÅŸaÄŸÄ±daki kod bloÄŸu, veri setindeki belirli bir sÃ¼tunu tamamen kÃ¼Ã§Ã¼k harfe Ã§evirerek normalize eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: \n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu mÃ¼thiÅŸ..\n",
      "film ise baÅŸyapÄ±t..\n",
      "10/10\n",
      "        \n",
      "            \n",
      "Ã‡IKTI: \n",
      "                      jean reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu mÃ¼thiÅŸ..\n",
      "film ise baÅŸyapÄ±t..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "text_column = \"comment\" \n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][4])\n",
    "\n",
    "df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "print(\"Ã‡IKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 2. AÅŸama: Noktalama Ä°ÅŸaretlerini Temizleme\n",
    "\n",
    "### **Neden Ã–nemlidir?**\n",
    "Metinlerdeki noktalama iÅŸaretleri, dilin yapÄ±sal Ã¶ÄŸeleri olup, modelin anlam Ã§Ä±karma ve analiz yapma konusunda yanÄ±ltÄ±cÄ± olabilir. Ã–rneÄŸin, bir cÃ¼mledeki noktalama iÅŸaretleri, genellikle anlam taÅŸÄ±mayan karakterlerdir. Noktalama iÅŸaretlerini temizlemek, metni daha uygun hale getirebilir.\n",
    "\n",
    "### ğŸ”¹ **Ã–rnek:**\n",
    "- **Girdi:** `\"Film harikaydÄ±, ancak biraz uzun.\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"film harikaydi ancak biraz uzun\"`\n",
    "\n",
    "### ğŸ› ï¸ **Noktalama Ä°ÅŸaretlerini Temizleme AdÄ±mlarÄ±:**\n",
    "Bu aÅŸamada, metinden tÃ¼m noktalama iÅŸaretlerini kaldÄ±racaÄŸÄ±z. Bunun iÃ§in **regex** kullanarak, metin iÃ§indeki noktalama iÅŸaretlerini temizleyeceÄŸiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: \n",
      "                      jean reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu mÃ¼thiÅŸ..\n",
      "film ise baÅŸyapÄ±t..\n",
      "10/10\n",
      "        \n",
      "            \n",
      "Ã‡IKTI: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu mÃ¼thiÅŸ\n",
      "film ise baÅŸyapÄ±t\n",
      "1010\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(\"GÄ°RDÄ°:\", df[text_column][4])\n",
    "\n",
    "df[text_column] = df[text_column].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "\n",
    "print(\"Ã‡IKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 3. AÅŸama: SayÄ±larÄ± Temizleme\n",
    "\n",
    "### **Neden Ã–nemlidir?**\n",
    "Metinlerde bulunan sayÄ±lar, genellikle model iÃ§in anlam taÅŸÄ±maz. EÄŸer verisetinde belirli bir sayÄ±sal bilgi yoksa ya da sayÄ±lar analizi etkilemeyecekse, bunlarÄ±n metinden Ã§Ä±karÄ±lmasÄ± gerekebilir. Ã–zellikle duygu analizi gibi gÃ¶revlerde sayÄ±lar, anlamlÄ± bir bilgi taÅŸÄ±maz. \n",
    "\n",
    "### ğŸ”¹ **Ã–rnek:**\n",
    "- **Girdi:** `\"Bu film 2021 yÄ±lÄ±nda vizyona girdi.\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"bu film yÄ±lÄ±nda vizyona girdi\"`\n",
    "\n",
    "### ğŸ› ï¸ **SayÄ±larÄ± Temizleme AdÄ±mlarÄ±:**\n",
    "Bu aÅŸamada, metindeki sayÄ±larÄ± kaldÄ±racaÄŸÄ±z. Bunun iÃ§in **regex** kullanarak sayÄ±larÄ± temizleyeceÄŸiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu mÃ¼thiÅŸ\n",
      "film ise baÅŸyapÄ±t\n",
      "1010\n",
      "        \n",
      "            \n",
      "Ã‡IKTI: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu mÃ¼thiÅŸ\n",
      "film ise baÅŸyapÄ±t\n",
      "\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(\"GÄ°RDÄ°:\", df[text_column][4])\n",
    "df[text_column] = df[text_column].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "print(\"Ã‡IKTI:\", df[text_column][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 4. AÅŸama: Stopwords (AnlamsÄ±z Kelimeleri) Temizleme\n",
    "\n",
    "### **Neden Ã–nemlidir?**\n",
    "**Stopwords**, dilin temel yapÄ± taÅŸlarÄ± olan ve genellikle anlam taÅŸÄ±mayan, Ã§ok sÄ±k kullanÄ±lan kelimelerdir. Bu kelimeler, modelin anlamlÄ± bilgi Ã¶ÄŸrenmesini engelleyebilir. Ã–rneÄŸin, \"ve\", \"bir\", \"ile\" gibi kelimeler bir cÃ¼mlenin anlamÄ±nÄ± deÄŸiÅŸtirmez, ancak metin analizinde yer almasÄ± modelin yanlÄ±ÅŸ Ã¶ÄŸrenmesine yol aÃ§abilir. Bu yÃ¼zden stopwords'leri metinden Ã§Ä±kararak metni sadeleÅŸtirebiliriz.\n",
    "\n",
    "### ğŸ”¹ **Ã–rnek:**\n",
    "- **Girdi:** `\"Film Ã§ok gÃ¼zeldi ve oyunculuk harikaydÄ±.\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"film gÃ¼zeldi oyunculuk harikaydÄ±\"`\n",
    "\n",
    "### ğŸ› ï¸ **Stopwords Temizleme AdÄ±mlarÄ±:**\n",
    "Bu adÄ±mda, TÃ¼rkÃ§e stopwords listesini kullanarak metin iÃ§indeki anlamsÄ±z kelimeleri temizleyeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/cilem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPWORDS: {'ama', 'ya', 'de', 'biri', 'siz', 'mÄ±', 'diye', 'hepsi', 'ki', 'ise', 'nerde', 'az', 'mu', 'bazÄ±', 'Ã§ok', 'en', 'veya', 'da', 'belki', 'aslÄ±nda', 'kez', 'ne', 'sanki', 'yani', 'mÃ¼', 'o', 'tÃ¼m', 'nerede', 'kim', 'eÄŸer', 'birÅŸey', 'neden', 'bu', 'her', 'hiÃ§', 'daha', 'ÅŸu', 'birkaÃ§', 've', 'hep', 'nereye', 'Ã§Ã¼nkÃ¼', 'hem', 'nasÄ±l', 'gibi', 'biz', 'iÃ§in', 'acaba', 'ile', 'ÅŸey', 'defa', 'niye', 'niÃ§in'}\n",
      "GÄ°RDÄ°: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu mÃ¼thiÅŸ\n",
      "film ise baÅŸyapÄ±t\n",
      "\n",
      "        \n",
      "            \n",
      "Ã‡IKTI: jean reno adam kusursuz oyunculugu mÃ¼thiÅŸ film baÅŸyapÄ±t\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('turkish'))\n",
    "print(\"STOPWORDS:\", stop_words)\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][4])\n",
    "df[text_column] = df[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "print(\"Ã‡IKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 5. AÅŸama: Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ±\n",
    "\n",
    "### **Neden Ã–nemlidir?**\n",
    "Metinlerdeki Ã¶zel karakterler ve emojiler, modelin doÄŸru ÅŸekilde Ã¶ÄŸrenmesi iÃ§in genellikle gereksizdir. Ã–zellikle duygu analizi veya metin sÄ±nÄ±flandÄ±rma gibi gÃ¶revlerde, bu semboller anlam taÅŸÄ±maz ve metnin doÄŸasÄ±na zarar verebilir. Bu yÃ¼zden, emojiler ve Ã¶zel karakterler, metin iÅŸleme sÃ¼recinde temizlenmesi gereken Ã¶ÄŸelerdir.\n",
    "\n",
    "### ğŸ”¹ **Ã–rnek:**\n",
    "- **Girdi:** `\"Film harikaydÄ±! ğŸ˜ğŸ¬ Ã‡ok eÄŸlenceliydi... :)\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"film harikaydi cok eglenceliydi\"`\n",
    "\n",
    "### ğŸ› ï¸ **Ã–zel Karakterlerin ve Emojilerin KaldÄ±rÄ±lmasÄ± AdÄ±mlarÄ±:**\n",
    "Bu adÄ±mda, metindeki tÃ¼m Ã¶zel karakterleri ve emojileri kaldÄ±racaÄŸÄ±z. Bunun iÃ§in regex kullanarak bu karakterleri temizleyeceÄŸiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: efsane geri dÃ¶ndÃ¼ ğŸ˜ korkuseansi cuma vizyonda korku seansi the conjuring tÄ±pkÄ± ilkinde olduÄŸu yaÅŸanmÄ±ÅŸ bir olaydan esinleniyor korku filmlerinden bildiÄŸimiz genel gerÃ§ek olaylardan esinlenmiÅŸtir tanÄ±mÄ±nÄ±n dÄ±ÅŸÄ±nda bir durum the conjuring korku seansÄ± â€ bir james wanâ€™Ä±n yÃ¶netiminde Ã¼nlÃ¼ demonologlar ed lorraine warrenâ€™Ä±n dosyalarÄ±ndan bir baÅŸka gerÃ§ek vakayÄ± ele alÄ±yor vera farmiga patrick wilsona iyice alÄ±ÅŸtÄ±k filmde yine etkileyiciliklerini koruyorlar paranormal olaylarÄ± yaÅŸayan janeti canlandÄ±ran madison wolfe kÃ¼Ã§Ã¼k yaÅŸÄ±na raÄŸmen rolÃ¼ kotarmÄ±ÅŸ james wan korku sinemasÄ± aÃ§Ä±sÄ±ndan Ã¶zel bir yÃ¶netmen son dÃ¶nemde etkileyici iÅŸler onun imzasÄ±nÄ± taÅŸÄ±yor yine etkileyici bir iÅŸe imza atmÄ±ÅŸ tempoyu dÃ¼ÅŸÃ¼rmemiÅŸ Ã¶zellikle filmin ortalarÄ±na kadar gerilim dozu tek bir an bile dÃ¼ÅŸmÃ¼yor\n",
      "Ã‡IKTI: efsane geri dondu  korkuseansi cuma vizyonda korku seansi the conjuring tipki ilkinde oldugu yasanmis bir olaydan esinleniyor korku filmlerinden bildigimiz genel gercek olaylardan esinlenmistir taniminin disinda bir durum the conjuring korku seansi  bir james wanin yonetiminde unlu demonologlar ed lorraine warrenin dosyalarindan bir baska gercek vakayi ele aliyor vera farmiga patrick wilsona iyice alistik filmde yine etkileyiciliklerini koruyorlar paranormal olaylari yasayan janeti canlandiran madison wolfe kucuk yasina ragmen rolu kotarmis james wan korku sinemasi acisindan ozel bir yonetmen son donemde etkileyici isler onun imzasini tasiyor yine etkileyici bir ise imza atmis tempoyu dusurmemis ozellikle filmin ortalarina kadar gerilim dozu tek bir an bile dusmuyor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_turkish_chars(text):\n",
    "    turkish_chars = {\n",
    "        'Ã§': 'c', 'Ä±': 'i', 'ÄŸ': 'g', 'ÅŸ': 's', 'Ã¼': 'u', 'Ã¶': 'o', 'Ã‡': 'C', 'Ä°': 'I', 'Ä': 'G', 'Å': 'S', 'Ãœ': 'U', 'Ã–': 'O'\n",
    "    }\n",
    "    for turkish_char, english_char in turkish_chars.items():\n",
    "        text = text.replace(turkish_char, english_char)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_special_characters_and_emojis(text):\n",
    "    text = convert_turkish_chars(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  \n",
    "    return text\n",
    "\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][588])\n",
    "df[text_column] = df[text_column].apply(remove_special_characters_and_emojis)\n",
    "print(\"Ã‡IKTI:\", df[text_column][588])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 6. AÅŸama: Metin Normalizasyonu (Text Normalization)\n",
    "\n",
    "### **Neden Ã–nemlidir?**\n",
    "Metin normalizasyonu, metinlerdeki varyasyonlarÄ± ortadan kaldÄ±rarak daha tutarlÄ± ve temiz veriler elde etmemizi saÄŸlar. Bu iÅŸlem, yazÄ±m hatalarÄ±, kÄ±saltmalar ve dildeki diÄŸer tutarsÄ±zlÄ±klarÄ±n dÃ¼zeltilmesine yardÄ±mcÄ± olur. Modelin daha etkili bir ÅŸekilde Ã¶ÄŸrenmesi iÃ§in metnin daha anlaÅŸÄ±lÄ±r ve dÃ¼zenli hale getirilmesi gereklidir.\n",
    "\n",
    "### ğŸ”¹ **Ã–rnek:**\n",
    "- **Girdi:** `\"YazÄ±lÄ±m olmyacak, ama tlfn alcam!\"`\n",
    "- **Ã‡Ä±ktÄ±:** `\"yazilim olmayacak ama telefon alacagim\"`\n",
    "\n",
    "### ğŸ› ï¸ **Metin Normalizasyonu AdÄ±mlarÄ±:**\n",
    "Bu adÄ±mda, yazÄ±m hatalarÄ±nÄ± dÃ¼zeltecek ve bazÄ± yaygÄ±n kÄ±saltmalarÄ± geniÅŸleterek daha standart bir forma dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz. Bunun iÃ§in bir kelime eÅŸlemesi (dictionary) kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: gzl bi filmdi izlemege deger\n",
      "Ã‡IKTI: guzel bi filmdi izlemege deger\n"
     ]
    }
   ],
   "source": [
    "normalization_dict = {\n",
    "    'tmm': 'tamam',\n",
    "    'gzl': 'guzel'\n",
    "}\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower() \n",
    "    for word, normalized_word in normalization_dict.items():\n",
    "        text = re.sub(r'\\b' + word + r'\\b', normalized_word, text)\n",
    "    return text\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][2232])\n",
    "\n",
    "df['comment'] = df['comment'].apply(normalize_text)\n",
    "\n",
    "print(\"Ã‡IKTI:\", df[text_column][2232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ **7. AÅŸama: KÃ¶k veya GÃ¶vdeye Ä°ndirgeme (Stemming & Lemmatization)**\n",
    "\n",
    "**Neden Ã–nemlidir?**  \n",
    "Metindeki kelimeleri kÃ¶klerine indirgeme (stemming) veya kÃ¶klerine en yakÄ±n hale getirme (lemmatization), kelimelerin farklÄ± biÃ§imlerini tek bir temsil ile ifade eder. Bu, modelin daha anlamlÄ± bir ÅŸekilde Ã§alÄ±ÅŸmasÄ±na yardÄ±mcÄ± olur. Ã–rneÄŸin, \"yazÄ±yorum\", \"yazdÄ±\" ve \"yazmak\" kelimeleri kÃ¶klerine indirgenerek hepsi \"yaz\" olarak iÅŸlenebilir. Bu, dilin Ã§eÅŸitli tÃ¼revlerinin anlamÄ±nÄ± birleÅŸtirir ve modelin Ã¶ÄŸrenmesini iyileÅŸtirir.\n",
    "\n",
    "---\n",
    "\n",
    "**Stemming ve Lemmatization ArasÄ±ndaki Farklar:**\n",
    "\n",
    "- **Stemming**: Kelimenin kÃ¶kÃ¼ne indirgeme iÅŸlemi yapar, ancak bazÄ± kelimeleri yanlÄ±ÅŸ kÃ¶klerle eÅŸleÅŸtirebilir. Ã–rneÄŸin, \"yazmak\" kelimesi \"yaz\" olarak indirgenir.\n",
    "  \n",
    "- **Lemmatization**: Daha geliÅŸmiÅŸ bir iÅŸlemdir. Kelimenin doÄŸru kÃ¶k biÃ§imini bulur. \"yazmak\" â†’ \"yaz\", \"gÃ¼zel\" â†’ \"gÃ¼zel\" gibi. Bu iÅŸlem iÃ§in bir kelime Ã§Ã¶zÃ¼mleyici (lemmatizer) kullanÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ï¸âƒ£ **Stemming Ã–rneÄŸi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jpype import startJVM, JClass, shutdownJVM\n",
    "ZEMBEREK_PATH = \"/home/cilem/Projects/nlp-applications/text-preprocessing/zemberek-full.jar\"  # DosyanÄ±n yolunu doÄŸru ÅŸekilde belirtmelisin\n",
    "\n",
    "# JVM baÅŸlat\n",
    "startJVM(classpath=ZEMBEREK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I|11:28:37.781|Root lexicon created in 588 ms.                                                                     | DictionarySerializer#getDictionaryItems\n",
      "I|11:28:37.783|Dictionary generated in 647 ms                                                                      | RootLexicon#defaultBinaryLexicon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: filmi cok duydum izlemek nasip oldu sonnunda bi hayal kirikligi yasadim leon mathilda arasindaki duygularin ask diye adlandirilmasini ki oyle yanni ben oyle anladimve bunu son derece insani filmden soguttugu dusuncesini paylasan arkadaslarla aynni fikirdeyim film oyunculuk yonetmelik bakimindan kusursuz ki zaten jreno tabiki v for vandettanin evey si oynuyor ikili arsinnda ki sevgi biraz afarkli sekilde yansitilabilirdi diye dusunuyorum hele elbiseyi giyip leona ilk iliskilerden bahsetme sahnesinde neredeyse kusacaktim olmamis diyorum konu sevgi bence yanlis yansitilmis yine oyunculuk yonetmenlik icinde ols verdim kadar sahnelerinde gozumu kapatmak zorunda kalsamda izlemek isteyen arkadaslara tavsiye ederim sonucta emek var muthis oyunculuk var\n",
      "Ã‡IKTI: ['film', 'cok', 'duy', 'izle', 'nasip', 'ol', 'sonnunda', 'bi', 'hayal', 'kirikligi', 'yasadim', 'leon', 'mathilda', 'arasindaki', 'duygularin', 'ask', 'diye', 'adlandirilmasini', 'ki', 'oyle', 'yanni', 'ben', 'oyle', 'anladimve', 'bu', 'son', 'derece', 'insani', 'film', 'soguttugu', 'dusuncesini', 'payla', 'arkadaslarla', 'aynni', 'fikir', 'film', 'oyun', 'yonetmelik', 'bakimindan', 'kusur', 'ki', 'zaten', 'jreno', 'tabiki', 'v', 'for', 'vandettanin', 'evey', 'si', 'oyn', 'iki', 'arsinnda', 'ki', 'sevgi', 'biraz', 'afarkli', 'sekil', 'yansitilabilirdi', 'diye', 'dusunuyorum', 'hele', 'elbise', 'giy', 'leon', 'ilk', 'iliskilerden', 'bahset', 'sahne', 'neredeyse', 'kusacaktim', 'olmamis', 'di', 'konu', 'sevgi', 'bence', 'yanlis', 'yansitilmis', 'yine', 'oyun', 'yonetmenlik', 'icinde', 'ols', 'ver', 'kadar', 'sahne', 'gozumu', 'kapat', 'zor', 'kalsamda', 'izle', 'iste', 'arkadaslara', 'tavsiye', 'ed', 'sonucta', 'emek', 'var', 'muthis', 'oyun', 'var']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I|11:28:38.482|Initialized in 1425 ms.                                                                             | TurkishMorphology#createWithDefaults\n"
     ]
    }
   ],
   "source": [
    "TurkishMorphology = JClass(\"zemberek.morphology.TurkishMorphology\")\n",
    "morphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "def stem(word):\n",
    "    analysis = morphology.analyze(word)\n",
    "    results = [str(result.getStem()) for result in analysis]\n",
    "    return results[0] if results else word\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][10])\n",
    "word_list = df[text_column][10].split()\n",
    "print(\"Ã‡IKTI:\", [stem(word) for word in word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ **Lemmatization Ã–rneÄŸi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: yapim hakkinda oyle yazabilirim kitap olur yuzden kisa kesmem lazim bir kere agladigim iki filmden birisidirdigeri yesil yol izledigim iyi film midir karar veremeyecegim izledigim sanatsal sahneleri barindiran luc besson harikasi oldugu kesindir oyunculardan sikca bahseldilmis konuya girmeyecegim luc besson abi sen cevher varmis demekten kendimi alamiyorum yonetmenlikten cabuk cekilerek kiytirik aksiyon filmlerine senaryo yazman yazik oldu gercekten ovgulerim eric serra icinde gecerlidir nitekim abartmiyorum filmin si eric serra nin hakkidir muhtesem melodilerine hayranim son olarak natalie portman a degineyim sen kadar tatli munis bir seymissin yahu kucukken ayri bir havan simdi ayri bir havan var yazalim dedik dokturmusum goruyorumki buradan anlayabilirsiniz hayatimin filmi oldugunu\n",
      "Ã‡IKTI: yapim hakkinda oyle yazabilirim kitap olur yuzden kisa kesmem lazim bir kere agladigim iki filmden birisidirdigeri yesil yol izledigim iyi film midir karar veremeyecegim izledigim sanatsal sahneleri barindiran luc besson harikasi oldugu kesindir oyunculardan sikca bahseldilmis konuya girmeyecegim luc besson abi sen cevher varmis demekten kendimi alamiyorum yonetmenlikten cabuk cekilerek kiytirik aksiyon filmlerine senaryo yazman yazik oldu gercekten ovgulerim eric serra icinde gecerlidir nitekim abartmiyorum filmin si eric serra nin hakkidir muhtesem melodilerine hayranim son olarak natalie portman a degineyim sen kadar tatli munis bir seymissin yahu kucukken ayri bir havan simdi ayri bir havan var yazalim dedik dokturmusum goruyorumki buradan anlayabilirsiniz hayatimin filmi oldugunu\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][2])\n",
    "\n",
    "print(\"Ã‡IKTI:\", lemmatization(df[text_column][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 8. AÅŸama: Kelime Tokenizasyonu (Tokenization)\n",
    "\n",
    "### ğŸš€ Neden Ã–nemlidir?\n",
    "Kelime tokenizasyonu, metni daha kÃ¼Ã§Ã¼k birimlere (kelime veya cÃ¼mlelere) ayÄ±rma iÅŸlemdir. DoÄŸal dil iÅŸleme (NLP) sÃ¼reÃ§lerinde veriyi daha anlamlÄ± hale getirmek iÃ§in temel bir adÄ±mdÄ±r.\n",
    "\n",
    "**Ã–rneÄŸin:**\n",
    "\n",
    "- **Kelime BazlÄ± Tokenizasyon:**  \n",
    "  *\"BugÃ¼n hava Ã§ok gÃ¼zel!\"*  \n",
    "  Tokenizasyon iÅŸlemi: `[\"BugÃ¼n\", \"hava\", \"Ã§ok\", \"gÃ¼zel\", \"!\"]`\n",
    "\n",
    "- **CÃ¼mle BazlÄ± Tokenizasyon:**  \n",
    "  *\"BugÃ¼n hava Ã§ok gÃ¼zel! DÄ±ÅŸarÄ± Ã§Ä±kalÄ±m mÄ±?\"*  \n",
    "  Tokenizasyon iÅŸlemi: `[\"BugÃ¼n hava Ã§ok gÃ¼zel!\", \"DÄ±ÅŸarÄ± Ã§Ä±kalÄ±m mÄ±?\"]`\n",
    "\n",
    "### ğŸ›  Tokenizasyon TÃ¼rleri\n",
    "1. **Kelime BazlÄ± Tokenizasyon:** CÃ¼mleyi kelimelere bÃ¶ler.\n",
    "2. **CÃ¼mle BazlÄ± Tokenizasyon:** Metni cÃ¼mlelere bÃ¶ler.\n",
    "3. **Alt Kelime (Subword) Tokenizasyonu:** Ã–zel karakterleri ve ekleri de hesaba katarak parÃ§alama yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GÄ°RDÄ°: jean reno denince zaten leon filmi gelir akla izlemeyen kalmamistir kaldiysada ee duruyorsun hemen izle\n",
      "Ã‡IKTI: ('jean reno denince zaten leon filmi gelir akla izlemeyen kalmamistir kaldiysada ee duruyorsun hemen izle',)\n",
      "Ã‡IKTI: ('jean', 'reno', 'denince', 'zaten', 'leon', 'filmi', 'gelir', 'akla', 'izlemeyen', 'kalmamistir', 'kaldiysada', 'ee', 'duruyorsun', 'hemen', 'izle')\n"
     ]
    }
   ],
   "source": [
    "from trtokenizer.tr_tokenizer import SentenceTokenizer, WordTokenizer\n",
    "\n",
    "\n",
    "sentence_tokenizer = SentenceTokenizer()\n",
    "\n",
    "print(\"GÄ°RDÄ°:\", df[text_column][0])\n",
    "\n",
    "print(\"Ã‡IKTI:\", sentence_tokenizer.tokenize(df[text_column][0]))\n",
    "\n",
    "word_tokenizer = WordTokenizer()\n",
    "\n",
    "print(\"Ã‡IKTI:\", word_tokenizer.tokenize(df[text_column][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
