{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 Metin Ön İşleme: Neden Önemlidir?\n",
    "\n",
    "Doğal Dil İşleme (NLP) projelerinde ham metin verisi, çoğu zaman doğrudan analiz veya modelleme için kullanılamaz. Metinler; düzensiz karakterler, noktalama işaretleri, gereksiz kelimeler ve biçimsel farklılıklar içerebilir. Bu nedenle, metinlerin doğru ve etkili bir şekilde işlenebilmesi için ön işleme adımları uygulanmalıdır.\n",
    "\n",
    "Metin ön işleme, veriyi daha temiz, tutarlı ve işlenebilir hale getirmek için yapılan bir dizi dönüşüm sürecini kapsar. Bu süreç, kullanılan modele ve uygulama alanına bağlı olarak değişebilir ancak genel olarak şu nedenlerle kritik bir öneme sahiptir:\n",
    "\n",
    "✅ **Gürültüyü Azaltma**: Gereksiz karakterler, semboller ve durak (stop) kelimelerinin kaldırılması, veriyi daha anlamlı hale getirir.  \n",
    "✅ **Veri Tutarlılığını Artırma**: Farklı biçimlerde yazılmış kelimeleri normalize etmek, metnin daha tutarlı olmasını sağlar.  \n",
    "✅ **Hesaplama Maliyetini Azaltma**: Gereksiz veriyi eleyerek modelin daha verimli çalışmasına yardımcı olur.  \n",
    "✅ **Genelleştirme Yeteneğini Artırma**: Kelime köklerine indirgeme (stemming/lemmatization) gibi işlemler, modelin farklı bağlamlarda da iyi performans göstermesini sağlar.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Metin Ön İşleme Aşamaları  \n",
    "\n",
    "Metin ön işleme süreci, çeşitli dönüşümleri içeren birden fazla adımdan oluşur:\n",
    "\n",
    "1️⃣ **Büyük/Küçük Harf Dönüşümü (Lowercasing)**: Metindeki tüm harflerin küçük harfe çevrilmesi.  \n",
    "2️⃣ **Noktalama İşaretlerinin Kaldırılması (Removing Punctuation)**: Noktalama işaretlerinin silinmesi veya gerektiğinde değiştirilmesi.  \n",
    "3️⃣ **Sayıların Kaldırılması (Removing Numbers)**: Sayıların metinden çıkarılması (bazı durumlarda korunabilir).  \n",
    "4️⃣ **Durak Kelimelerin Kaldırılması (Removing Stopwords)**: \"ve\", \"bu\", \"bir\" gibi bilgi taşımayan yaygın kelimelerin çıkarılması.  \n",
    "5️⃣ **Özel Karakterlerin ve Emojilerin Kaldırılması (Removing Special Characters & Emojis)**: Metindeki özel sembollerin ve emojilerin temizlenmesi.  \n",
    "6️⃣ **Metin Normalizasyonu (Text Normalization)**: Kelimelerin standart bir forma dönüştürülmesi (örneğin, \"olmıyacak\" → \"olmayacak\", \"tlfn\" → \"telefon\").  \n",
    "7️⃣ **Kök veya Gövdeye İndirgeme (Stemming & Lemmatization)**: Kelimeleri kök haline getirme (stemming) veya köküne en yakın hâle getirme (lemmatization).  \n",
    "8️⃣ **Kelime Tokenizasyonu (Tokenization)**: Metni kelime veya cümlelere ayırma.  \n",
    "9️⃣ **Kelime Frekans Analizi (Word Frequency Analysis)**: En sık kullanılan kelimelerin belirlenmesi ve sayılması.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/cilem/.cache/kagglehub/datasets/mustfkeskin/turkish-movie-sentiment-analysis-dataset/versions/1\n",
      "Dataset name: turkish_movie_sentiment_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "path = kagglehub.dataset_download(\"mustfkeskin/turkish-movie-sentiment-analysis-dataset\")\n",
    "dataset_name = os.listdir(path)[0]\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"Dataset name:\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                      Jean Reno denince zate...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                      Ekşın falan izlemek is...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                      Bu yapım hakkında öyle...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                      finali yeter... (sting...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n                      Jean Reno..\\r\\nbu adam...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name point\n",
       "0  \\n                      Jean Reno denince zate...  Sevginin Gücü   5,0\n",
       "1  \\n                      Ekşın falan izlemek is...  Sevginin Gücü   5,0\n",
       "2  \\n                      Bu yapım hakkında öyle...  Sevginin Gücü   5,0\n",
       "3  \\n                      finali yeter... (sting...  Sevginin Gücü   5,0\n",
       "4  \\n                      Jean Reno..\\r\\nbu adam...  Sevginin Gücü   5,0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path, dataset_name))\n",
    "print(df[\"comment\"][4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 1. Aşama: Lowercasing (Küçük Harfe Çevirme)\n",
    "\n",
    "**Neden Önemlidir?**  \n",
    "Metinlerde büyük/küçük harf duyarlılığı nedeniyle aynı kelimeler farklı şekilde yorumlanabilir.  \n",
    "Örneğin, \"Film\" ve \"film\" kelimeleri aslında aynıdır, ancak büyük harf farkı nedeniyle farklı olarak algılanabilir.  \n",
    "Bunu önlemek için tüm metni küçük harfe çevirmeliyiz.\n",
    "\n",
    "### 🔹 Örnek:\n",
    "- **Girdi:** `\"Bu Film HARİKAYDI!\"`\n",
    "- **Çıktı:** `\"bu film harikaydı!\"`\n",
    "\n",
    "Aşağıdaki kod bloğu, veri setindeki belirli bir sütunu tamamen küçük harfe çevirerek normalize eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: \n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n",
      "ÇIKTI: \n",
      "                      jean reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "text_column = \"comment\" \n",
    "\n",
    "print(\"GİRDİ:\", df[text_column][4])\n",
    "\n",
    "df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "print(\"ÇIKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 2. Aşama: Noktalama İşaretlerini Temizleme\n",
    "\n",
    "### **Neden Önemlidir?**\n",
    "Metinlerdeki noktalama işaretleri, dilin yapısal öğeleri olup, modelin anlam çıkarma ve analiz yapma konusunda yanıltıcı olabilir. Örneğin, bir cümledeki noktalama işaretleri, genellikle anlam taşımayan karakterlerdir. Noktalama işaretlerini temizlemek, metni daha uygun hale getirebilir.\n",
    "\n",
    "### 🔹 **Örnek:**\n",
    "- **Girdi:** `\"Film harikaydı, ancak biraz uzun.\"`\n",
    "- **Çıktı:** `\"film harikaydi ancak biraz uzun\"`\n",
    "\n",
    "### 🛠️ **Noktalama İşaretlerini Temizleme Adımları:**\n",
    "Bu aşamada, metinden tüm noktalama işaretlerini kaldıracağız. Bunun için **regex** kullanarak, metin içindeki noktalama işaretlerini temizleyeceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: \n",
      "                      jean reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n",
      "ÇIKTI: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu müthiş\n",
      "film ise başyapıt\n",
      "1010\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(\"GİRDİ:\", df[text_column][4])\n",
    "\n",
    "df[text_column] = df[text_column].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "\n",
    "print(\"ÇIKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 3. Aşama: Sayıları Temizleme\n",
    "\n",
    "### **Neden Önemlidir?**\n",
    "Metinlerde bulunan sayılar, genellikle model için anlam taşımaz. Eğer verisetinde belirli bir sayısal bilgi yoksa ya da sayılar analizi etkilemeyecekse, bunların metinden çıkarılması gerekebilir. Özellikle duygu analizi gibi görevlerde sayılar, anlamlı bir bilgi taşımaz. \n",
    "\n",
    "### 🔹 **Örnek:**\n",
    "- **Girdi:** `\"Bu film 2021 yılında vizyona girdi.\"`\n",
    "- **Çıktı:** `\"bu film yılında vizyona girdi\"`\n",
    "\n",
    "### 🛠️ **Sayıları Temizleme Adımları:**\n",
    "Bu aşamada, metindeki sayıları kaldıracağız. Bunun için **regex** kullanarak sayıları temizleyeceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu müthiş\n",
      "film ise başyapıt\n",
      "1010\n",
      "        \n",
      "            \n",
      "ÇIKTI: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu müthiş\n",
      "film ise başyapıt\n",
      "\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(\"GİRDİ:\", df[text_column][4])\n",
    "df[text_column] = df[text_column].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "print(\"ÇIKTI:\", df[text_column][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 4. Aşama: Stopwords (Anlamsız Kelimeleri) Temizleme\n",
    "\n",
    "### **Neden Önemlidir?**\n",
    "**Stopwords**, dilin temel yapı taşları olan ve genellikle anlam taşımayan, çok sık kullanılan kelimelerdir. Bu kelimeler, modelin anlamlı bilgi öğrenmesini engelleyebilir. Örneğin, \"ve\", \"bir\", \"ile\" gibi kelimeler bir cümlenin anlamını değiştirmez, ancak metin analizinde yer alması modelin yanlış öğrenmesine yol açabilir. Bu yüzden stopwords'leri metinden çıkararak metni sadeleştirebiliriz.\n",
    "\n",
    "### 🔹 **Örnek:**\n",
    "- **Girdi:** `\"Film çok güzeldi ve oyunculuk harikaydı.\"`\n",
    "- **Çıktı:** `\"film güzeldi oyunculuk harikaydı\"`\n",
    "\n",
    "### 🛠️ **Stopwords Temizleme Adımları:**\n",
    "Bu adımda, Türkçe stopwords listesini kullanarak metin içindeki anlamsız kelimeleri temizleyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/cilem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPWORDS: {'ise', 'mı', 'veya', 'tüm', 'neden', 'acaba', 'biri', 'o', 'defa', 'için', 'siz', 'şu', 'hepsi', 'şey', 'niçin', 'gibi', 'nerede', 'biz', 'her', 'ama', 've', 'daha', 'eğer', 'hem', 'nereye', 'az', 'birkaç', 'birşey', 'en', 'de', 'mü', 'nerde', 'ya', 'sanki', 'belki', 'diye', 'kim', 'çok', 'çünkü', 'bazı', 'ki', 'bu', 'hiç', 'yani', 'mu', 'hep', 'nasıl', 'ne', 'ile', 'da', 'kez', 'niye', 'aslında'}\n",
      "GİRDİ: \n",
      "                      jean reno\n",
      "bu adam kusursuz biri\n",
      "ve oyunculugu müthiş\n",
      "film ise başyapıt\n",
      "\n",
      "        \n",
      "            \n",
      "ÇIKTI: jean reno adam kusursuz oyunculugu müthiş film başyapıt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('turkish'))\n",
    "print(\"STOPWORDS:\", stop_words)\n",
    "\n",
    "print(\"GİRDİ:\", df[text_column][4])\n",
    "df[text_column] = df[text_column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "print(\"ÇIKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 5. Aşama: Özel Karakterlerin ve Emojilerin Kaldırılması\n",
    "\n",
    "### **Neden Önemlidir?**\n",
    "Metinlerdeki özel karakterler ve emojiler, modelin doğru şekilde öğrenmesi için genellikle gereksizdir. Özellikle duygu analizi veya metin sınıflandırma gibi görevlerde, bu semboller anlam taşımaz ve metnin doğasına zarar verebilir. Bu yüzden, emojiler ve özel karakterler, metin işleme sürecinde temizlenmesi gereken öğelerdir.\n",
    "\n",
    "### 🔹 **Örnek:**\n",
    "- **Girdi:** `\"Film harikaydı! 😍🎬 Çok eğlenceliydi... :)\"`\n",
    "- **Çıktı:** `\"film harikaydi cok eglenceliydi\"`\n",
    "\n",
    "### 🛠️ **Özel Karakterlerin ve Emojilerin Kaldırılması Adımları:**\n",
    "Bu adımda, metindeki tüm özel karakterleri ve emojileri kaldıracağız. Bunun için regex kullanarak bu karakterleri temizleyeceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: efsane geri döndü 😎 korkuseansi cuma vizyonda korku seansi the conjuring tıpkı ilkinde olduğu yaşanmış bir olaydan esinleniyor korku filmlerinden bildiğimiz genel gerçek olaylardan esinlenmiştir tanımının dışında bir durum the conjuring korku seansı ” bir james wan’ın yönetiminde ünlü demonologlar ed lorraine warren’ın dosyalarından bir başka gerçek vakayı ele alıyor vera farmiga patrick wilsona iyice alıştık filmde yine etkileyiciliklerini koruyorlar paranormal olayları yaşayan janeti canlandıran madison wolfe küçük yaşına rağmen rolü kotarmış james wan korku sineması açısından özel bir yönetmen son dönemde etkileyici işler onun imzasını taşıyor yine etkileyici bir işe imza atmış tempoyu düşürmemiş özellikle filmin ortalarına kadar gerilim dozu tek bir an bile düşmüyor\n",
      "ÇIKTI: efsane geri dondu  korkuseansi cuma vizyonda korku seansi the conjuring tipki ilkinde oldugu yasanmis bir olaydan esinleniyor korku filmlerinden bildigimiz genel gercek olaylardan esinlenmistir taniminin disinda bir durum the conjuring korku seansi  bir james wanin yonetiminde unlu demonologlar ed lorraine warrenin dosyalarindan bir baska gercek vakayi ele aliyor vera farmiga patrick wilsona iyice alistik filmde yine etkileyiciliklerini koruyorlar paranormal olaylari yasayan janeti canlandiran madison wolfe kucuk yasina ragmen rolu kotarmis james wan korku sinemasi acisindan ozel bir yonetmen son donemde etkileyici isler onun imzasini tasiyor yine etkileyici bir ise imza atmis tempoyu dusurmemis ozellikle filmin ortalarina kadar gerilim dozu tek bir an bile dusmuyor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_turkish_chars(text):\n",
    "    turkish_chars = {\n",
    "        'ç': 'c', 'ı': 'i', 'ğ': 'g', 'ş': 's', 'ü': 'u', 'ö': 'o', 'Ç': 'C', 'İ': 'I', 'Ğ': 'G', 'Ş': 'S', 'Ü': 'U', 'Ö': 'O'\n",
    "    }\n",
    "    for turkish_char, english_char in turkish_chars.items():\n",
    "        text = text.replace(turkish_char, english_char)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_special_characters_and_emojis(text):\n",
    "    text = convert_turkish_chars(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  \n",
    "    return text\n",
    "\n",
    "\n",
    "print(\"GİRDİ:\", df[text_column][588])\n",
    "df[text_column] = df[text_column].apply(remove_special_characters_and_emojis)\n",
    "print(\"ÇIKTI:\", df[text_column][588])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 6. Aşama: Metin Normalizasyonu (Text Normalization)\n",
    "\n",
    "### **Neden Önemlidir?**\n",
    "Metin normalizasyonu, metinlerdeki varyasyonları ortadan kaldırarak daha tutarlı ve temiz veriler elde etmemizi sağlar. Bu işlem, yazım hataları, kısaltmalar ve dildeki diğer tutarsızlıkların düzeltilmesine yardımcı olur. Modelin daha etkili bir şekilde öğrenmesi için metnin daha anlaşılır ve düzenli hale getirilmesi gereklidir.\n",
    "\n",
    "### 🔹 **Örnek:**\n",
    "- **Girdi:** `\"Yazılım olmyacak, ama tlfn alcam!\"`\n",
    "- **Çıktı:** `\"yazilim olmayacak ama telefon alacagim\"`\n",
    "\n",
    "### 🛠️ **Metin Normalizasyonu Adımları:**\n",
    "Bu adımda, yazım hatalarını düzeltecek ve bazı yaygın kısaltmaları genişleterek daha standart bir forma dönüştüreceğiz. Bunun için bir kelime eşlemesi (dictionary) kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: gzl bi filmdi izlemege deger\n",
      "ÇIKTI: guzel bi filmdi izlemege deger\n"
     ]
    }
   ],
   "source": [
    "normalization_dict = {\n",
    "    'tmm': 'tamam',\n",
    "    'gzl': 'guzel'\n",
    "}\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower() \n",
    "    for word, normalized_word in normalization_dict.items():\n",
    "        text = re.sub(r'\\b' + word + r'\\b', normalized_word, text)\n",
    "    return text\n",
    "\n",
    "print(\"GİRDİ:\", df[text_column][2232])\n",
    "\n",
    "df['comment'] = df['comment'].apply(normalize_text)\n",
    "\n",
    "print(\"ÇIKTI:\", df[text_column][2232])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 **7. Aşama: Kök veya Gövdeye İndirgeme (Stemming & Lemmatization)**\n",
    "\n",
    "**Neden Önemlidir?**  \n",
    "Metindeki kelimeleri köklerine indirgeme (stemming) veya köklerine en yakın hale getirme (lemmatization), kelimelerin farklı biçimlerini tek bir temsil ile ifade eder. Bu, modelin daha anlamlı bir şekilde çalışmasına yardımcı olur. Örneğin, \"yazıyorum\", \"yazdı\" ve \"yazmak\" kelimeleri köklerine indirgenerek hepsi \"yaz\" olarak işlenebilir. Bu, dilin çeşitli türevlerinin anlamını birleştirir ve modelin öğrenmesini iyileştirir.\n",
    "\n",
    "---\n",
    "\n",
    "**Stemming ve Lemmatization Arasındaki Farklar:**\n",
    "\n",
    "- **Stemming**: Kelimenin köküne indirgeme işlemi yapar, ancak bazı kelimeleri yanlış köklerle eşleştirebilir. Örneğin, \"yazmak\" kelimesi \"yaz\" olarak indirgenir.\n",
    "  \n",
    "- **Lemmatization**: Daha gelişmiş bir işlemdir. Kelimenin doğru kök biçimini bulur. \"yazmak\" → \"yaz\", \"güzel\" → \"güzel\" gibi. Bu işlem için bir kelime çözümleyici (lemmatizer) kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ **Stemming Örneği:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
