{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/cilem/.cache/kagglehub/datasets/mustfkeskin/turkish-movie-sentiment-analysis-dataset/versions/1\n",
      "Dataset name: turkish_movie_sentiment_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas\n",
    "#%pip install nltk\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import ngrams\n",
    "\n",
    "path = kagglehub.dataset_download(\"mustfkeskin/turkish-movie-sentiment-analysis-dataset\")\n",
    "dataset_name = os.listdir(path)[0]\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"Dataset name:\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                      Jean Reno denince zate...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                      Ekşın falan izlemek is...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                      Bu yapım hakkında öyle...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                      finali yeter... (sting...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n                      Jean Reno..\\r\\nbu adam...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name point\n",
       "0  \\n                      Jean Reno denince zate...  Sevginin Gücü   5,0\n",
       "1  \\n                      Ekşın falan izlemek is...  Sevginin Gücü   5,0\n",
       "2  \\n                      Bu yapım hakkında öyle...  Sevginin Gücü   5,0\n",
       "3  \\n                      finali yeter... (sting...  Sevginin Gücü   5,0\n",
       "4  \\n                      Jean Reno..\\r\\nbu adam...  Sevginin Gücü   5,0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path, dataset_name))\n",
    "print(df[\"comment\"][4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GİRDİ: \n",
      "                      Jean Reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n",
      "ÇIKTI: \n",
      "                      jean reno..\n",
      "bu adam kusursuz biri..\n",
      "ve oyunculugu müthiş..\n",
      "film ise başyapıt..\n",
      "10/10\n",
      "        \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "text_column = \"comment\" \n",
    "\n",
    "print(\"GİRDİ:\", df[text_column][4])\n",
    "\n",
    "df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "print(\"ÇIKTI:\", df[text_column][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 3313153),\n",
       " ('\\n', 165451),\n",
       " ('bir', 136714),\n",
       " ('ve', 72910),\n",
       " ('bu', 56740),\n",
       " ('film', 49167),\n",
       " ('çok', 48471),\n",
       " ('de', 28795),\n",
       " ('ama', 27887),\n",
       " ('filmi', 25606)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams = []\n",
    "for sent in df[text_column]:\n",
    "    word = sent.split(\" \")\n",
    "    unigrams.extend(word)\n",
    "\n",
    "unigram_freq = FreqDist(unigrams)\n",
    "\n",
    "unigram_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('', ''), 3049118),\n",
       " (('\\n', ''), 164982),\n",
       " (('', '\\n'), 164768),\n",
       " (('bir', 'film'), 16707),\n",
       " (('güzel', 'bir'), 5310),\n",
       " (('bu', 'kadar'), 5156),\n",
       " (('bu', 'film'), 4993),\n",
       " (('bir', 'film.'), 4860),\n",
       " (('en', 'iyi'), 4838),\n",
       " (('bu', 'filmi'), 4752)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(ngrams(unigrams, 2))\n",
    "\n",
    "bigram_freqs = FreqDist(bigrams)\n",
    "bigram_freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('', '', ''), 2801130),\n",
       " (('\\n', '', ''), 164935),\n",
       " (('', '\\n', ''), 164592),\n",
       " (('', '', '\\n'), 164521),\n",
       " (('', '', 'film'), 3828),\n",
       " (('', '', 'bu'), 3701),\n",
       " (('', '', 'çok'), 3417),\n",
       " (('', '', 'bence'), 2058),\n",
       " (('film.\\n', '', ''), 1930),\n",
       " (('', '', 'filmi'), 1908)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = list(ngrams(unigrams, 3))\n",
    "\n",
    "trigram_freqs = FreqDist(trigrams)\n",
    "trigram_freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def unigram_predict(last_word, unigram_freq):\n",
    "\n",
    "    most_common = unigram_freq.most_common()\n",
    "    predictions = [word for word, _ in most_common] \n",
    "    return random.choice(predictions)\n",
    "\n",
    "\n",
    "def bigram_predict(last_word, bigram_freqs):\n",
    "    possible_bigrams = [bigram for bigram in bigram_freqs if bigram[0] == last_word]\n",
    "    if possible_bigrams:\n",
    "        next_words = [bigram[1] for bigram in possible_bigrams]\n",
    "        return random.choice(next_words)\n",
    "    else:\n",
    "        return None \n",
    "    \n",
    "\n",
    "def trigram_predict(last_two_words, trigram_freqs):\n",
    "    \n",
    "    possible_trigrams = [trigram for trigram in trigram_freqs if trigram[0] == last_two_words[0] and trigram[1] == last_two_words[1]]\n",
    "    if possible_trigrams:\n",
    "        next_words = [trigram[2] for trigram in possible_trigrams]\n",
    "        return random.choice(next_words)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Tahmini: arananlar\n",
      "Bigram Tahmini: olduğu\n",
      "Trigram Tahmini: oluyor.\n"
     ]
    }
   ],
   "source": [
    "input_word = \"güzel\" \n",
    "\n",
    "unigram_prediction = unigram_predict(input_word, unigram_freq)\n",
    "print(f\"Unigram Tahmini: {unigram_prediction}\")\n",
    "\n",
    "bigram_prediction = bigram_predict(input_word, bigram_freqs)\n",
    "print(f\"Bigram Tahmini: {bigram_prediction}\")\n",
    "\n",
    "input_words = [\"film\", \"güzel\"]  \n",
    "trigram_prediction = trigram_predict(input_words, trigram_freqs)\n",
    "print(f\"Trigram Tahmini: {trigram_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
